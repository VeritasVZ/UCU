{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indoor localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An indoor positioning system (IPS) is a system to locate objects or people inside a building using radio waves, magnetic fields, acoustic signals, or other sensory information collected by mobile devices. There are several commercial systems on the market, but there is no standard for an IPS system.\n",
    "\n",
    "IPSes use different technologies, including distance measurement to nearby anchor nodes (nodes with known positions, e.g., WiFi access points), magnetic positioning, dead reckoning. They either actively locate mobile devices and tags or provide ambient location or environmental context for devices to get sensed.\n",
    "\n",
    "According to the [report](https://www.marketsandmarkets.com/Market-Reports/indoor-positioning-navigation-ipin-market-989.html), the global indoor location market size is expected to grow from USD 7.11 Billion in 2017 to USD 40.99 Billion by 2022, at a Compound Annual Growth Rate (CAGR) of 42.0% during the forecast period. Hassle-free navigation, improved decision-making, and increased adoption of connected devices are boosting the growth of the indoor location market across the globe.\n",
    "\n",
    "In this problem, you are going to use signals from seven different wi-fi access points to define in which room the user is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data and breaking it into training and cross-validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pandas.read_csv('train_set.csv')\n",
    "cv_set = pandas.read_csv('cv_set.csv')\n",
    "\n",
    "train_data = train_set[['wifi'+str(i) for i in range(1, len(train_set.columns) - 1)]]\n",
    "train_labels = train_set['room']\n",
    "cv_data = cv_set[['wifi'+str(i) for i in range(1, len(cv_set.columns) - 1)]]\n",
    "cv_labels = cv_set['room']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wifi1  wifi2  wifi3  wifi4  wifi5  wifi6  wifi7\n",
      "0    -68    -57    -61    -65    -71    -85    -85\n",
      "1    -63    -60    -60    -67    -76    -85    -84\n",
      "2    -61    -60    -68    -62    -77    -90    -80\n",
      "3    -65    -61    -65    -67    -69    -87    -84\n",
      "4    -61    -63    -58    -66    -74    -87    -82\n",
      "5    -62    -60    -66    -68    -80    -86    -91\n",
      "6    -65    -59    -61    -67    -72    -86    -81\n",
      "7    -63    -57    -61    -65    -73    -84    -84\n",
      "8    -66    -60    -65    -62    -70    -85    -83\n",
      "9    -67    -60    -59    -61    -71    -86    -91\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "Name: room, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:10])\n",
    "print(train_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wifi1  wifi2  wifi3  wifi4  wifi5  wifi6  wifi7\n",
      "0    -64    -56    -61    -66    -71    -82    -81\n",
      "1    -63    -65    -60    -63    -77    -81    -87\n",
      "2    -64    -55    -63    -66    -76    -88    -83\n",
      "3    -65    -60    -59    -63    -76    -86    -82\n",
      "4    -67    -61    -62    -67    -77    -83    -91\n",
      "5    -61    -59    -65    -63    -74    -89    -87\n",
      "6    -63    -56    -63    -65    -72    -82    -89\n",
      "7    -66    -59    -64    -68    -68    -97    -83\n",
      "8    -67    -57    -64    -71    -75    -89    -87\n",
      "9    -63    -57    -59    -67    -71    -82    -93\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "Name: room, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cv_data[:10])\n",
    "print(cv_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1603.000000\n",
       "mean        2.503431\n",
       "std         1.109130\n",
       "min         1.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         3.000000\n",
       "max         4.000000\n",
       "Name: room, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.describe()\n",
    "# train_data.sample(5, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgboost.DMatrix(train_data, label=train_labels)\n",
    "dtest = xgboost.DMatrix(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Accuracy score:\t0.9824\n",
      "--F1 score:\t0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vzinkevych\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "m = model.fit(train_data,train_labels)\n",
    "preds = m.predict(cv_data)\n",
    "print('--Accuracy score:\\t{metric:.4f}'.format(metric=accuracy_score(y_pred=preds, y_true=cv_labels)))\n",
    "print('--F1 score:\\t{metric:.4f}'.format(metric=f1_score(y_pred=preds, y_true=cv_labels, average = 'macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp, Trials, fmin, tpe\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        self._model = None\n",
    "        self._best_params = None\n",
    "        self._best_score = None\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the model\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        space = {\n",
    "            'eta':\n",
    "               scope.float(hp.qloguniform('dtree_eta', np.log(1e-4), np.log(1), 1e-5)),\n",
    "#             'gamma':\n",
    "#                scope.int(hp.qloguniform('dtree_gamma', np.log(1), np.log(1000), 1)),\n",
    "            'max_depth':\n",
    "                scope.int(hp.qloguniform('dtree_max_depth', np.log(1), np.log(100), 1)),\n",
    "#             'min_child_weight': \n",
    "#                 scope.int(hp.qloguniform('min_child_weight', np.log(1), np.log(100), 1)),\n",
    "            'subsample':\n",
    "                scope.float(hp.qloguniform('dtree_subsample', np.log(0.5), np.log(1), 1e-2)),\n",
    "            'lambda':\n",
    "                scope.int(hp.qloguniform('dtree_lambda', np.log(1e-2), np.log(100), 1)),\n",
    "            'alpha':\n",
    "            \n",
    "                scope.int(hp.qloguniform('dtree_alpha', np.log(1e-2), np.log(100), 1))\n",
    "            \n",
    "            }\n",
    "        # fit the model\n",
    "        trials = Trials()\n",
    "        max_evals = 100\n",
    "        best = fmin(\n",
    "            fn=lambda params: self.train(x_train=x_train, \n",
    "                                         y_train=y_train, \n",
    "                                         seed=1234\n",
    "                                        ),\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials=trials,\n",
    "            rstate=np.random.RandomState(1234),\n",
    "        )\n",
    "\n",
    "        self._best_params = hyperopt.space_eval(space, best)\n",
    "        self._best_score = -trials.best_trial['result']['loss']\n",
    "        print('Best params:\\n{}'.format(self._best_params))\n",
    "\n",
    "        self._model = xgboost.XGBClassifier(seed=1234, **dict(**self._best_params))\n",
    "        self._model.fit(x_train, y_train)\n",
    "\n",
    "    @staticmethod\n",
    "    def train(x_train, y_train, **kwargs):\n",
    "        \"\"\"\n",
    "        Function to optimize - random forest model trained and tested with hyperparameters\n",
    "\n",
    "        :param kwargs: hyperparameters for the sklearn.ensemble.RandomForestClassifier\n",
    "        \"\"\"\n",
    "        \n",
    "        train_data = xgboost.DMatrix(x_train, label=y_train)\n",
    "        \n",
    "        rf = xgboost.XGBClassifier(**kwargs)\n",
    "        cv = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
    "        metric = cross_val_score(rf, x_train, y_train, cv=cv,\n",
    "                                 scoring='neg_log_loss',\n",
    "                                 )\n",
    "        return metric[1]\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.model.predict(x_test)\n",
    "\n",
    "    def predict_proba(self, x_test):\n",
    "        return self.model.predict_proba(x_test)\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "\n",
    "    @property\n",
    "    def best_params(self):\n",
    "        return self._best_params\n",
    "\n",
    "    @property\n",
    "    def best_score(self):\n",
    "        return self._best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'alpha': 0, 'eta': 0.30800000000000005, 'lambda': 0, 'max_depth': 2, 'subsample': 0.85}\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.fit(\n",
    "    x_train=train_data,\n",
    "    y_train=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Accuracy:\t0.9824\n",
      "--F1 score:\t0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vzinkevych\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "proba = model.predict_proba(x_test=cv_data)\n",
    "preds = model.predict(x_test=cv_data)\n",
    "\n",
    "print('--Accuracy:\\t{metric:.4f}'.format(metric=accuracy_score(y_pred=preds, y_true=cv_labels)))\n",
    "print('--F1 score:\\t{metric:.4f}'.format(metric=f1_score(y_pred=preds, y_true=cv_labels, average = 'macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
